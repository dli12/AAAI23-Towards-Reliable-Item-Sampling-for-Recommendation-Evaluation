{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3262d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6d36d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15887b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.9.0+cu111', '1.19.5', '1.0.5')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__, np.__version__, pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "756414cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import NeuMF, GMF, MLP\n",
    "from model_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69512d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'pinterest-20'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "348ca8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55187, 9916)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/processed_data/'\n",
    "\n",
    "data_reader = DataReader(data_path, dataset)\n",
    "\n",
    "validation_data_path = '../data/validation_data/'\n",
    "validation_u_dict = np.load(validation_data_path + dataset + '_dict.npy', allow_pickle = True).item()\n",
    "\n",
    "num_user, num_item = data_reader.get_user_item()\n",
    "\n",
    "num_user, num_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54037ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "decay = 0\n",
    "drop = 0\n",
    "emb_dim = 64\n",
    "epochs = 20 # for 20 small set\n",
    "\n",
    " # numbers of negative samples for each positive pair\n",
    "n_train = 2\n",
    "\n",
    "layers = [512, 256, 64] \n",
    "train_batch_size = 1024 # 128 for small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21aa6da",
   "metadata": {},
   "source": [
    "# 1. Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f097812",
   "metadata": {},
   "source": [
    "## 1.1 train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53124854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9fa1e3a9d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 9876543\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7683cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the modell based on recall@10\n",
    "best_r10 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df1d1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(num_user, num_item, layers[0]//2, layers).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1b9dd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:44, 89.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, time: 72.667329\n",
      "0.3036765905013862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 295.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, time: 21.982971\n",
      "0.4216753945675612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 302.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, time: 21.988950\n",
      "0.47117980683856703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 294.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, time: 22.193068\n",
      "0.4954246471089206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 291.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, time: 22.600959\n",
      "0.5070215811694783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:14, 275.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, time: 22.990844\n",
      "0.5128925290376357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:52, 75.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, time: 61.411121\n",
      "0.5147770308224763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 287.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, time: 22.779664\n",
      "0.5152843966876257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:14, 277.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, time: 22.866583\n",
      "0.5170964176345878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 289.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, time: 22.680915\n",
      "0.5171326580535271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [01:15, 52.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, time: 90.920209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 300.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, time: 21.970392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:12, 307.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, time: 23.732979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 299.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, time: 22.115664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 287.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, time: 22.679348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 291.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, time: 23.995183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 296.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, time: 22.639739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:13, 288.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, time: 22.580708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:27, 144.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, time: 56.922207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3965it [00:38, 102.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, time: 47.336349\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    # TD: train data pipeline\n",
    "    train_dataloader = data_reader.bce_getTrain(n_train, train_batch_size, g)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch_data in tqdm(enumerate(train_dataloader)):\n",
    "        \n",
    "        user = batch_data['user'].long().to(device) \n",
    "        item = batch_data['item'].long().to(device)\n",
    "        label = batch_data['label'].float().to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss = model.loss(user, item, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "    t1 = time.time()\n",
    "    print(\"epoch %d, time: %f\"%(epoch, t1-t0))\n",
    "    with torch.no_grad():\n",
    "         \n",
    "        model.eval()\n",
    "    \n",
    "        r10 =  sample_eval(model, validation_u_dict, device)\n",
    "        \n",
    "        if r10 > best_r10:\n",
    "            \n",
    "            '''\n",
    "            save model/parameters\n",
    "            save best result\n",
    "            save hyper parameter\n",
    "            '''\n",
    "            print(r10)\n",
    "            best_r10 = r10\n",
    "            save_model(model, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f45a1f6",
   "metadata": {},
   "source": [
    "## 1.2 Train GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a64fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9fa1e3a8e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 9876543\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85fb811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the modell based on recall@10\n",
    "best_r10 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d39610bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GMF(num_user, num_item, emb_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff174a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, time: 17.062950\n",
      "0.43066301846449345\n",
      "epoch 1, time: 17.106619\n",
      "0.4828492217370033\n",
      "epoch 2, time: 18.858264\n",
      "0.501005671625564\n",
      "epoch 3, time: 16.861352\n",
      "0.506604816351677\n",
      "epoch 4, time: 17.040522\n",
      "epoch 5, time: 17.203972\n",
      "epoch 6, time: 17.003726\n",
      "epoch 7, time: 17.038839\n",
      "epoch 8, time: 76.241969\n",
      "epoch 9, time: 16.710382\n",
      "epoch 10, time: 16.789539\n",
      "epoch 11, time: 16.600480\n",
      "epoch 12, time: 57.090421\n",
      "epoch 13, time: 17.039946\n",
      "epoch 14, time: 17.259862\n",
      "epoch 15, time: 17.026448\n",
      "epoch 16, time: 16.793561\n",
      "epoch 17, time: 90.886832\n",
      "epoch 18, time: 16.986647\n",
      "epoch 19, time: 17.245611\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    # TD: train data pipeline\n",
    "    train_dataloader = data_reader.bce_getTrain(n_train, train_batch_size, g)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch_data in enumerate(train_dataloader):\n",
    "        \n",
    "        user = batch_data['user'].long().to(device) \n",
    "        item = batch_data['item'].long().to(device)\n",
    "        label = batch_data['label'].float().to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss = model.loss(user, item, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "    t1 = time.time()\n",
    "    print(\"epoch %d, time: %f\"%(epoch, t1-t0))\n",
    "    with torch.no_grad():\n",
    "         \n",
    "        model.eval()\n",
    "    \n",
    "        r10 =  sample_eval(model, validation_u_dict, device)\n",
    "        \n",
    "        if r10 > best_r10:\n",
    "            \n",
    "            '''\n",
    "            save model/parameters\n",
    "            save best result\n",
    "            save hyper parameter\n",
    "            '''\n",
    "            print(r10)\n",
    "            best_r10 = r10\n",
    "            save_model(model, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a918d7d",
   "metadata": {},
   "source": [
    "## 1.3 Train NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53946ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9fa1e3aed0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 9876543\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6d81c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the modell based on recall@10\n",
    "best_r10 = 0\n",
    "pre_train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12dfbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuMF(num_user, num_item, emb_dim, layers).to(device)\n",
    "\n",
    "if pre_train:\n",
    "    GMF_model = torch.load('saved_model/' + dataset + '/GMF.pt')\n",
    "    MLP_model = torch.load('saved_model/' + dataset +'/MLP.pt')\n",
    "    model.load_pretrain(GMF_model, MLP_model)\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48cc426f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, time: 25.989233\n",
      "0.5156649210864878\n",
      "epoch 1, time: 26.096897\n",
      "epoch 2, time: 25.764883\n",
      "epoch 3, time: 91.433042\n",
      "epoch 4, time: 26.153516\n",
      "epoch 5, time: 26.007377\n",
      "epoch 6, time: 26.175897\n",
      "epoch 7, time: 26.229991\n",
      "epoch 8, time: 26.282748\n",
      "epoch 9, time: 25.806694\n",
      "epoch 10, time: 26.120638\n",
      "epoch 11, time: 30.980459\n",
      "epoch 12, time: 85.084320\n",
      "epoch 13, time: 25.891925\n",
      "epoch 14, time: 26.205854\n",
      "epoch 15, time: 26.028074\n",
      "epoch 16, time: 26.180645\n",
      "epoch 17, time: 26.030196\n",
      "epoch 18, time: 27.061328\n",
      "epoch 19, time: 25.777225\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    # TD: train data pipeline\n",
    "    train_dataloader = data_reader.bce_getTrain(n_train, train_batch_size, g)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch_data in enumerate(train_dataloader):\n",
    "        \n",
    "        user = batch_data['user'].long().to(device) \n",
    "        item = batch_data['item'].long().to(device)\n",
    "        label = batch_data['label'].float().to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss = model.loss(user, item, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "    t1 = time.time()\n",
    "    print(\"epoch %d, time: %f\"%(epoch, t1-t0))\n",
    "    with torch.no_grad():\n",
    "         \n",
    "        model.eval()\n",
    "    \n",
    "        r10 =  sample_eval(model, validation_u_dict, device)\n",
    "        \n",
    "        if r10 > best_r10:\n",
    "            \n",
    "            '''\n",
    "            save model/parameters\n",
    "            save best result\n",
    "            save hyper parameter\n",
    "            '''\n",
    "            print(r10)\n",
    "            best_r10 = r10\n",
    "            save_model(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b784251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
